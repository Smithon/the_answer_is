{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from gensim import corpora\n",
    "\n",
    "class MyDocument(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            with open(os.path.join(self.dirname, fname)) as content_file:\n",
    "                content = content_file.read()  \n",
    "                content = unicode(content, encoding='utf-8', errors='replace')\n",
    "                yield content.lower().split()\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            for line in open(os.path.join(self.dirname, fname)):\n",
    "                line = unicode(line, encoding='utf-8', errors='replace')\n",
    "                yield line.lower().split()\n",
    "\n",
    "def get_dictionary(path):\n",
    "    dictionary = corpora.Dictionary( MySentences(path) )\n",
    "    stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
    "    dictionary.filter_tokens(stop_ids) # remove stop words and words that appear only once\n",
    "    dictionary.compactify() # remove gaps in id sequence after words that were removed\n",
    "    return dictionary\n",
    "\n",
    "def get_document_tuple( path, dictionary ):\n",
    "    vector = pd.Series()\n",
    "    doclist = MyDocument(path) \n",
    "    for i,content in enumerate(doclist):\n",
    "        vector = vector.set_value(i,dictionary.doc2bow(content))\n",
    "    return list(vector)\n",
    "\n",
    "def transform_tuple_into_vector(document_tuple,dictionary):\n",
    "    vector = pd.Series(np.zeros(len(dictionary.token2id)))        #0 array for storing wiki document vectors.\n",
    "    if not document_tuple == []:\n",
    "        for onetuple in document_tuple: \n",
    "            vector[onetuple[0]] = onetuple[1]\n",
    "        vector = vector / np.linalg.norm(vector, ord = 1)                       #normalize vector     \n",
    "        return vector \n",
    "    else:\n",
    "        return vector\n",
    "\n",
    "def transform_tuples_into_dataframe(document_tuples, dictionary):\n",
    "    length = len(document_tuples) \n",
    "    vector_initialization = pd.Series(np.zeros(len(dictionary.token2id)))  #0 array for storing wiki document vectors. \n",
    "    df_vector = pd.DataFrame(vector_initialization)  #initialize dataframe. all vectors will be stored. \n",
    "    for i in xrange(len(document_tuples)):           \n",
    "        #for each wiki documents, we will transform wiki vectors in tuple form into\n",
    "        #vectors in ususal form. \n",
    "        vector = transform_tuple_into_vector( document_tuples[i], dictionary )\n",
    "        df_vector[i]= pd.DataFrame(vector)\n",
    "    return df_vector\n",
    "\n",
    "def get_close_documents(string, dataframe, dictionary, topn):\n",
    "    #string = unicode(string, encoding='utf-8', errors='replace').lower()\n",
    "    #print string\n",
    "    string = string_stemmer(string)\n",
    "    first_vector = transform_tuple_into_vector(dictionary.doc2bow(string.split()), dictionary )\n",
    "    #print first_vector\n",
    "    lengthlist = pd.Series()\n",
    "    for j in xrange(len(dataframe.columns)):\n",
    "        #lengthlist = lengthlist.set_value(j, np.linalg.norm(first_vector-dataframe[j]) )\n",
    "        lengthlist = lengthlist.set_value( j, spatial.distance.cosine(first_vector, dataframe[j]))\n",
    "    return lengthlist.sort_values().head(topn)\n",
    "\n",
    "def get_document_by_index(path,index):\n",
    "    # this gets the filename and content of the document in a directory by index. \n",
    "    i= 0\n",
    "    for fname in os.listdir(path):\n",
    "        if i == index:\n",
    "            with open(os.path.join(path, fname)) as content_file:\n",
    "                content = content_file.read()  \n",
    "                content = unicode(content, encoding='utf-8', errors='replace')\n",
    "                return fname, content\n",
    "        i= i + 1\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_contents_of_close_documents_by_paragraph(path, close_documents_list):\n",
    "    merged = ''\n",
    "    for i in close_documents_list.index:\n",
    "        name, text = get_document_by_index(path,i)\n",
    "        merged = merged + '\\n' + text        \n",
    "    return merged.split('\\n')\n",
    "\n",
    "\n",
    "def get_distance_between_two_documents(A, B, dictionary):\n",
    "    import re\n",
    "    if A:\n",
    "        A = re.sub(r'[^a-zA-Z ]',r'',A).lower().split()\n",
    "    else:\n",
    "        A = ['the']        # just in case A, or B is empty. \n",
    "    A = dictionary.doc2bow(A)\n",
    "    A = transform_tuple_into_vector( A ,dictionary)\n",
    "    \n",
    "    if B:\n",
    "        B = re.sub(r'[^a-zA-Z ]',r'',B).lower().split()\n",
    "    else:\n",
    "        B = ['the']       # just in case A, or B is empty. \n",
    "    B = dictionary.doc2bow(B)\n",
    "    B = transform_tuple_into_vector( B ,dictionary)\n",
    "    length = spatial.distance.cosine(A,B)\n",
    "    # I would like to use cosine distance, but the vectors are so sparse that most of the time the output is 0 .\n",
    "    # So we use euclidean distance. \n",
    "    #length = np.linalg.norm(A-B)\n",
    "    return length\n",
    "\n",
    "\n",
    "def string_stemmer(line):\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.snowball import SnowballStemmer\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    line = re.sub(r'[^a-zA-Z ]',r'',line)\n",
    "    line = line.split()\n",
    "    line = [word for word in line if word not in stopwords.words('english')]  # remove the stop words. \n",
    "    output = []\n",
    "    for word in line:\n",
    "        output.append(stemmer.stem(word))     #stem all words \n",
    "    output = ' '.join(output)           # join the list to make a string\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_my_answer_all_distance(train, dictionary, df_vector, wiki_path):\n",
    "    correct = 0\n",
    "    convert_answer = {3: 'A', 4: 'B', 5: 'C', 6: 'D' }\n",
    "    myanswer = pd.Series()    #initialize dataframe to store my answers\n",
    "    myanswer_distance = pd.DataFrame(np.zeros(4).reshape(1,4), columns = ['A','B','C','D'])    #initialize dataframe to store my answers distance\n",
    "    for i in xrange(len(train)):       #loop through all questions\n",
    "        q = train.ix[i][1]\n",
    "        \n",
    "        close_documents = get_close_documents(q, df_vector, dictionary,5)\n",
    "        merged = get_contents_of_close_documents_by_paragraph(wiki_path, close_documents)\n",
    "        four_choices = pd.Series()         # initialize a series to store the best value for each answer. \n",
    "        for j in [3,4,5,6]:            # the columns where the answer option lies. \n",
    "            A = train.ix[i][1] + ' ' + train.ix[i][j]       # question + each answer choice. \n",
    "            dist_list = []             # for storing all distance between A and all paragraphs in close documents. \n",
    "            for m in xrange(len(merged)):\n",
    "                distance = get_distance_between_two_documents(A, merged[m], dictionary)\n",
    "                if distance > 0:  #to disregrad nan value\n",
    "                    dist_list.append( distance )\n",
    "            if dist_list == []:\n",
    "                dist_list = [1]\n",
    "            four_choices = four_choices.set_value( j, min(dist_list)  )\n",
    "            #print np.std(dist_list)\n",
    "            #print min(dist_list) \n",
    "        myanswer_distance.set_value(i, 'A', four_choices[3] )\n",
    "        myanswer_distance.set_value(i, 'B', four_choices[4] )\n",
    "        myanswer_distance.set_value(i, 'C', four_choices[5] )\n",
    "        myanswer_distance.set_value(i, 'D', four_choices[6] )\n",
    "        myanswer = myanswer.set_value(i, convert_answer[ four_choices.argmin() ])\n",
    "        print 'question: ',q\n",
    "        print 'answer: ',train.ix[i][3], train.ix[i][4] ,train.ix[i][5], train.ix[i][6]\n",
    "        print 'correct answer: ', train.ix[i][2]\n",
    "        print i, four_choices[3], four_choices[4], four_choices[5], four_choices[6]\n",
    "        print 'my answer: ', convert_answer[ four_choices.argmin() ]\n",
    "        if train.ix[i][2] == convert_answer[ four_choices.argmin() ]:\n",
    "            correct = correct +1.0\n",
    "        print 'percent correct: ', correct / (i+1) \n",
    "    return myanswer_distance, myanswer\n",
    "\n",
    "\n",
    "\n",
    "def run_fetch_ws(train_file_path, dictionary_folder_path, wiki_folder_path):\n",
    "    dictionary = get_dictionary(dictionary_folder_path)\n",
    "    wiki_tuple = get_document_tuple( wiki_folder_path, dictionary )\n",
    "    df_wiki_vector = transform_tuples_into_dataframe(wiki_tuple,dictionary)  \n",
    "    train = pd.read_table(train_file_path,sep = '\\t')\n",
    "    distance, answer = get_my_answer_all_distance(train, dictionary, df_wiki_vector, wiki_folder_path)\n",
    "    \n",
    "    train['fetch_doc_ws_train_answer'] = answer\n",
    "    train['fetch_doc_ws_train_correct'] = (train['correctAnswer'] == train['fetch_doc_ws_train_answer'])\n",
    "    print 'percent correct is ' , train['fetch_doc_ws_train_correct'].sum(axis =0) / (len(train) + 0.0)\n",
    "    train.to_csv('/Users/MK/GitHub/the_answer_is/data/answer/fetch_doc_ws_train.csv', encoding='utf-8')\n",
    "    \n",
    "    return distance, answer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "stoplist = [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours',\n",
    "             u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', \n",
    "             u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', \n",
    "             u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', \n",
    "             u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', \n",
    "             u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', \n",
    "             u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', \n",
    "             u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', \n",
    "             u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', \n",
    "             u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', \n",
    "             u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', \n",
    "             u'should', u'now']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question:  When athletes begin to exercise, their heart rates and respiration rates increase.  At what level of organization does the human body coordinate these functions?\n",
      "answer:  at the tissue level at the organ level at the system level at the cellular level\n",
      "correct answer:  C\n",
      "0 0.759992319631 0.775493372467 0.75 0.775493372467\n",
      "my answer:  C\n",
      "percent correct:  1.0\n",
      "question:  Which example describes a learned behavior in a dog?\n",
      "answer:  smelling the air for odors barking when disturbed sitting on command digging in soil\n",
      "correct answer:  C\n",
      "1 0.42264973081 0.292893218813 0.292893218813 0.42264973081\n",
      "my answer:  B\n",
      "percent correct:  0.5\n",
      "question:  When two nuclei are combined into one nucleus, there is a slight change in mass and the release of a large amount of energy. What is this process called?\n",
      "answer:  conversion reaction fission fusion\n",
      "correct answer:  D\n",
      "2 0.643487952046 0.626998076704 0.663877217756 0.663877217756\n",
      "my answer:  B\n",
      "percent correct:  0.333333333333\n",
      "question:  Which is a distinction between an epidemic and a pandemic?\n",
      "answer:  the symptoms of the disease the geographical area affected the species of organisms infected the season in which the disease spreads\n",
      "correct answer:  B\n",
      "3 1.0 0.904217371478 1.0 0.820394697973\n",
      "my answer:  D\n",
      "percent correct:  0.25\n",
      "question:  In which way is the orbit of a comet different from the orbit of Earth?\n",
      "answer:  The orbit of Earth is less circular than the orbit of a comet. The orbit of a comet is more elliptical than the orbit of Earth. The orbital period of Earth is much longer than the orbital period of a comet. The orbital period of a comet is more predictable than the orbital period of Earth.\n",
      "correct answer:  B\n",
      "4 0.198216274263 0.167949705662 0.367544467966 0.333333333333\n",
      "my answer:  B\n",
      "percent correct:  0.4\n",
      "question:  A teacher builds a model of a hydrogen atom. A red golf ball is used for a proton, and a green golf ball is used for an electron. Which is not accurate concerning the model?\n",
      "answer:  number of particles relative mass of particles types of particles present charges of particles present\n",
      "correct answer:  B\n",
      "5 0.5527864045 0.5527864045 0.5527864045 0.5527864045\n",
      "my answer:  A\n",
      "percent correct:  0.333333333333\n",
      "question:  Which substance should a student apply to the skin if he or she gets splashed with an acid?\n",
      "answer:  water vinegar salt formaldehyde\n",
      "correct answer:  A\n",
      "6 0.499226604333 0.5 0.5 0.42264973081\n",
      "my answer:  D\n",
      "percent correct:  0.285714285714\n",
      "question:  What is the main source of energy for the water cycle?\n",
      "answer:  the Sun fossil fuels clouds the ocean\n",
      "correct answer:  A\n",
      "7 0.42264973081 0.42264973081 0.292893218813 0.42264973081\n",
      "my answer:  C\n",
      "percent correct:  0.25\n",
      "question:  Which has the greatest effect on aiding the movement of blood through the human body?\n",
      "answer:  tension friction density gravity\n",
      "correct answer:  D\n",
      "8 0.367544467966 0.42264973081 0.367544467966 0.367544467966\n",
      "my answer:  A\n",
      "percent correct:  0.222222222222\n",
      "question:  Over time, non-volcanic mountains can form due to the interaction of plate boundaries. Which interaction is most likely associated with the formation of non-volcanic mountains?\n",
      "answer:  oceanic plates colliding with oceanic plates oceanic plates separating from oceanic plates continental plates colliding with continental plates continental plates separating from continental plates\n",
      "correct answer:  C\n",
      "9 0.702955737107 0.702955737107 0.702955737107 0.702955737107\n",
      "my answer:  A\n",
      "percent correct:  0.2\n",
      "question:  The human body has an average, normal temperature of about 98.6Â°F. To keep the core body temperature from becoming too high, the brain sends a signal to the body to\n",
      "answer:  decrease sugar levels in the blood. increase sugar levels in the blood. decrease blood flow to the skin. increase blood flow to the skin.\n",
      "correct answer:  D\n",
      "10 0.904653741075 0.904653741075 0.840199306975 0.840199306975\n",
      "my answer:  C\n",
      "percent correct:  0.181818181818\n",
      "question:  Which is the best explanation of the term ecology?\n",
      "answer:  the study of the nonliving parts of the environment the study of the living parts of the environment the study of the protection and renewal of natural resources the study of organisms and their interactions with the environment\n",
      "correct answer:  D\n",
      "11 0.741801110253 0.741801110253 0.683772233983 0.741801110253\n",
      "my answer:  C\n",
      "percent correct:  0.166666666667\n",
      "question:  A farmer sprayed his orange trees with a pesticide to eliminate the insects damaging the trees. Some of the insects survived and produced offspring that were also resistant to the insecticide. Which process is illustrated by the pesticide resistance of the offspring?\n",
      "answer:  natural selection selective breeding aerobic respiration sexual reproduction\n",
      "correct answer:  A\n",
      "12 0.591751709536 0.591751709536 0.591751709536 0.646446609407\n",
      "my answer:  A\n",
      "percent correct:  0.230769230769\n",
      "question:  Researchers work in teams to make cars more fuel efficient. Which of these statements describes the main advantage of working in teams rather than working individually?\n",
      "answer:  The research is more likely to be published. The research costs less to perform. The researchers can share their ideas. The researchers have more time to complete work.\n",
      "correct answer:  C\n",
      "13 0.711324865405 0.745999746 0.711324865405 0.528595479209\n",
      "my answer:  D\n",
      "percent correct:  0.214285714286\n",
      "question:  Achromatopsia is a genetic disorder in which sufferers have no color vision.  Achromatopsia MOST likely affects which of the following structures in the eye?\n",
      "answer:  rod cells cone cells lens iris\n",
      "correct answer:  B\n",
      "14 0.292893218813 0.292893218813 0.292893218813 0.244071053982\n",
      "my answer:  D\n",
      "percent correct:  0.2\n",
      "question:  Which of these elements is likely to be found in an organic compound?\n",
      "answer:  helium hydrogen mercury tin\n",
      "correct answer:  B\n",
      "15 0.42264973081 0.42264973081 0.292893218813 0.292893218813\n",
      "my answer:  C\n",
      "percent correct:  0.1875\n",
      "question:  Which statement describes a principle scientists have used to learn more about the structure of Earth's interior?\n",
      "answer:  Solid materials absorb seismic waves. Magnetic fields deflect seismic waves. The density of a material affects the speed of a seismic wave. The physical state of a material determines the amplitude of a seismic wave.\n",
      "correct answer:  C\n",
      "16 0.591751709536 0.5527864045 0.591751709536 0.591751709536\n",
      "my answer:  B\n",
      "percent correct:  0.176470588235\n",
      "question:  A scientist looks at a graph that shows the percentages of humus, clay, and sand that make up a soil. If the scientist had the total weight of each material, instead of percentages, what type of graph would be best to illustrate the data?\n",
      "answer:  bar graph scatterplot circle graph pictograph\n",
      "correct answer:  A\n",
      "17 0.411651594585 0.525658350975 0.4 0.525658350975\n",
      "my answer:  C\n",
      "percent correct:  0.166666666667\n",
      "question:  Robots can perform tasks that are dangerous for humans. What is the MAJOR limitation to the use of robots?\n",
      "answer:  The assembly pieces must be very small. The assembly process must remain exactly the same. Robots require regular maintenance. Robots must be provided with electricity.\n",
      "correct answer:  B\n",
      "18 0.5527864045 0.591751709536 0.5 0.5\n",
      "my answer:  C\n",
      "percent correct:  0.157894736842\n",
      "question:  A student investigated the percentage of energy obtained from several food sources for a population of eagles. Which format is the best way to display this data?\n",
      "answer:  a table a pie chart a bar graph a line graph\n",
      "correct answer:  B\n",
      "19 0.702329721106 0.737479489784 0.737479489784 0.737479489784\n",
      "my answer:  A\n",
      "percent correct:  0.15\n",
      "question:  The Voyager II space probe was launched in 1979 with the mission of flying past the outer gas giant planets and collecting data.  What unit of measurement would BEST describe the distance that this probe traveled to reach Neptune?\n",
      "answer:  meters kilometers astronomical units light years\n",
      "correct answer:  C\n",
      "20 0.46966991411 0.46966991411 0.46966991411 0.485504244572\n",
      "my answer:  A\n",
      "percent correct:  0.142857142857\n",
      "question:  Which cellular structure allows nutrients to pass into cells?\n",
      "answer:  mitochondrion nucleus membrane chloroplast\n",
      "correct answer:  C\n",
      "21 0.5 0.591751709536 0.5 0.591751709536\n",
      "my answer:  A\n",
      "percent correct:  0.136363636364\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-28e7d7cbbcc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmy_train_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/MK/GitHub/the_answer_is/data/training_set.tsv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmy_dictionary_folder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/MK/GitHub/the_answer_is/data/temporary2'\u001b[0m  \u001b[0;31m#this folder contains one file which is stemmed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mrun_fetch_ws\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_train_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_dictionary_folder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmy_wiki_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-4cd736874f50>\u001b[0m in \u001b[0;36mrun_fetch_ws\u001b[0;34m(train_file_path, dictionary_folder_path, wiki_folder_path)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mdf_wiki_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_tuples_into_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_tuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0mdistance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_my_answer_all_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_wiki_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwiki_folder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fetch_doc_ws_train_answer'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4cd736874f50>\u001b[0m in \u001b[0;36mget_my_answer_all_distance\u001b[0;34m(train, dictionary, df_vector, wiki_path)\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mdist_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m             \u001b[0;31m# for storing all distance between A and all paragraphs in close documents.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                 \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_distance_between_two_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m#to disregrad nan value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                     \u001b[0mdist_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdistance\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4cd736874f50>\u001b[0m in \u001b[0;36mget_distance_between_two_documents\u001b[0;34m(A, B, dictionary)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'the'\u001b[0m\u001b[0;34m]\u001b[0m       \u001b[0;31m# just in case A, or B is empty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_tuple_into_vector\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mB\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspatial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcosine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# I would like to use cosine distance, but the vectors are so sparse that most of the time the output is 0 .\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-4cd736874f50>\u001b[0m in \u001b[0;36mtransform_tuple_into_vector\u001b[0;34m(document_tuple, dictionary)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_tuple_into_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_tuple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mvector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m#0 array for storing wiki document vectors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdocument_tuple\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0monetuple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument_tuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MK/anaconda/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    219\u001b[0m                                        raise_cast_failure=True)\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MK/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, block, axis, do_integrity_check, fastpath)\u001b[0m\n\u001b[1;32m   3623\u001b[0m             block = make_block(block,\n\u001b[1;32m   3624\u001b[0m                                \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3625\u001b[0;31m                                ndim=1, fastpath=True)\n\u001b[0m\u001b[1;32m   3626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3627\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/MK/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mmake_block\u001b[0;34m(values, placement, klass, ndim, dtype, fastpath)\u001b[0m\n\u001b[1;32m   2310\u001b[0m                dtype=None, fastpath=False):\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2312\u001b[0;31m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2313\u001b[0m         \u001b[0mvtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_wiki_folder_path = '/Users/MK/GitHub/the_answer_is/data/wikipedia_stemmed_all_merged'\n",
    "my_train_file_path = '/Users/MK/GitHub/the_answer_is/data/training_set.tsv'\n",
    "my_dictionary_folder_path = '/Users/MK/GitHub/the_answer_is/data/temporary2'  #this folder contains one file which is stemmed. \n",
    "distance, answer  = run_fetch_ws(my_train_file_path, my_dictionary_folder_path, my_wiki_folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
